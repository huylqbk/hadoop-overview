
# HDFS: What is it and how it works

The hadoop distributed file systems.
# KeyNote
- HDFS
  - files are split into 64MB blocks (chunks)
  - blocks are stored on DataNodes (machnies with date)
  - each block is stored 3 times on different nodes
    - if DataNode goes down the NameNode notices this and re-replicates the data to have 3 copies again
  - metadata about files is stored on the NameNode
    - if metadata is lost due to disk failure - all the data on DataNodes is lost as well (we can not re-construct it from blocks)
    - the second NameNode can be configured as a standby replica of the active NameNode
  - hadoop fs - allows to view and manipulate the file system, works with unix-like commands
    - hadoop fs -ls - list files
    - hadoop fs -put filename.txt - add a file to hadoop fs
    - hadoop fs -mv filename.txt newname.txt
    - hadoop fs -rm newname.txt
    - hadoop fs -mkdir newdir
    - hadoop fs -put filename.txt newdir
    - hadoop fs -ls newdir
    - hadoop fs -tail filename.txt - show tail of the file
    - hadoop fs -cat filename.txt - show the whole file
    - hadoop fs -get filename.txt localname.txt - copy file to the local filesystem

- MapReduce
  - MapReduce process
    - file is broken into chunks and processed in parallel
      - initial chunks are passed to mappers, mappers pre-process data into intermediate records
        - all data is in form of key, value
      - by default chunks for MapReduce are HDFS blocks (chunks the original file was split to)
    - shuffle and sort stage
      - shuffle - movement of intermediate records from mappers to reducers
      - sort - reducers organize records they got
    - reducer works then on each set of sorted records, it gets a key and a list of values for that key
      - final results are stored back to HDFS
    - to get final results sorted - we can do an extra step or use only one reducer and get sorted data from it (one reducer doesn't scale well)

# Overview

* Handles large files
    - Can be logs with info from sensors, etc
* Does this by breaking into blocks
    - Blocks are quite large - 128megs by default (big files)
    - If less than that goes to only 1 block
    - No limitations for single hard drive
    - Also allows to distribute processing of the large files
        + Different computers can process a chunk of data
* Blocks can be stored across commodity computer
    - Store more than one copy of each block
    - If computers go down, its' possible to use backups
    - If single block goes down, we don't lose info
    - This is the power of HDFS
    - Don't need special computers with high availability as if it doesn't work we can use another node

## HDFS Architecture

* **Name node** There is a name node: file name on virtual dir structure
    - It knows where to go 
    - There is an EDIT LOG to keep track where everything is
* **Data node** - What actually stores each block of each file
    - Nodes talk to each other

## Example: Reading a file

Client node needs to access data in HDFS.

* Talk to node
    - Node comes back and says which nodes are the data
    - Then we have to go to the specific nodes to retrieve the data
    - Under the hood the HDFS figures out where to get, how to get, etc
    - Also it knows which ones are the most efficient

## Example: Writing a file

* Client wants to create a new file
    - Name node keeps track of new entries and its blocks
    - Then creates an entry, then client talks to data node with file/data
    - Then nodes talk to each other to replicate the data across nodes
    - Once data is stored, there is an acknowledgement sent back
    
## Namenode resilience

* Backup metadata
    - Namenode writes to local disk and NFS
    - It's possible to re-boot from this
    - There will be some lag with writing the data
    - If you can tolerate downtime, this is the simplest way
* Secondary Namenode
    - It's not a hot backup
    - It's a merged copy of edit log you can restore from
    - Little bit better than previous solution
* HDFS Federation
    - Each namenode manages a specific namespace volume
    - You might have a lot of small files, and namenodes can't fit more data
    - HDFS federation manages multiple namespaces for a specific volume
    - You can spread out the namenodes
    - If one of the namenodes goes down, you don't loose all the data
* HDFS High Availability
    - If you can't stand any downtime
    - Hot standby namenode using shared edit log
    - Writing to file system that is not HDFS
    - Backup can take up
    - Uses Zookeeper to keep track which node is active at any given time
    - Uses extreme measures to ensure only one namenode is used at a time

# Using HDFS

* Can use UI (Ambari)
    - Just looks like a big hard drive (across loads of servers, etc)
    - Command Line Interface
    - HTTP/HDFS Proxies
    - Java interface 
    - NFS Gateway - Mounting a remote file system





